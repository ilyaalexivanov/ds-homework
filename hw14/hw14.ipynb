{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сверточные нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Реализовать СНН на MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "FOLDER = 'MNIST_data'\n",
    "\n",
    "if not os.path.exists(FOLDER):\n",
    "    os.mkdir(FOLDER)\n",
    "    \n",
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# данные\n",
    "train_set = datasets.MNIST(root=FOLDER, train=True, transform=trans, download=True)\n",
    "test_set = datasets.MNIST(root=FOLDER, train=False, transform=trans, download=True)\n",
    "\n",
    "# итераторы\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "sample_x, sample_y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (prelu1): PReLU(num_parameters=1)\n",
      "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (prelu2): PReLU(num_parameters=1)\n",
      "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, (5,5), padding=2)\n",
    "        self.prelu1 = nn.PReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "#        self.bn1 = CustomBatchNorm2d(6)\n",
    "        self.conv2 = nn.Conv2d(6, 16, (5,5))\n",
    "        self.prelu2 = nn.PReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(self.bn1(self.prelu1(self.conv1(x))), (2,2))\n",
    "        x = F.max_pool2d(self.bn2(self.prelu2(self.conv2(x))), (2,2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.1)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = LeNet()\n",
    "print (net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; Accuracy train: 95.735%\n",
      "Epoch: 1; Accuracy train: 97.650%\n",
      "Epoch: 2; Accuracy train: 97.830%\n",
      "Epoch: 3; Accuracy train: 97.992%\n",
      "Epoch: 4; Accuracy train: 98.225%\n",
      "Epoch: 5; Accuracy train: 98.185%\n",
      "Epoch: 6; Accuracy train: 98.458%\n",
      "Epoch: 7; Accuracy train: 98.442%\n",
      "Epoch: 8; Accuracy train: 98.370%\n",
      "Epoch: 9; Accuracy train: 98.410%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    # trainning\n",
    "    av_loss = 0.\n",
    "    correct = 0.\n",
    "#    for x, y in tqdm.tqdm(train_loader):\n",
    "    for x, y in train_loader:\n",
    "        # рассчитываем функцию потерь\n",
    "        out = net(x)\n",
    "        loss = criterion(out, y)\n",
    "        # оптимизация параметров\n",
    "        ## первым шагом обнулим градиенты предыдущего шага (важный момент,\n",
    "        ## без этого результаты теряют корректность)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # подсчет статистики за эпоху        \n",
    "        pred = out.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "        av_loss += loss.item()\n",
    "    print('Epoch: {}; Accuracy train: {:.3f}%'.format(epoch, correct / len(train_loader.dataset) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9; Accuracy train: 98.570%\n"
     ]
    }
   ],
   "source": [
    "av_loss = 0.\n",
    "correct = 0.\n",
    "for x, y in test_loader:\n",
    "    # рассчитываем функцию потерь\n",
    "    out = net(x)\n",
    "    loss = criterion(out, y)\n",
    "    # подсчет статистики за эпоху        \n",
    "    pred = out.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "    av_loss += loss.item()\n",
    "print('Epoch: {}; Accuracy train: {:.3f}%'.format(epoch, correct / len(test_loader.dataset) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custrom BatchNorm2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBatchNorm2d(nn.BatchNorm2d):\n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = y.view(x.size(1), -1)\n",
    "        mu = y.mean(dim=1)\n",
    "        sigma2 = y.var(dim=1)\n",
    "        if self.training is not True:\n",
    "            y = y - self.running_mean.view(-1, 1)\n",
    "            y = y / (self.running_var.view(-1, 1)**.5 + self.eps)\n",
    "        else:\n",
    "            if self.track_running_stats is True:\n",
    "                with torch.no_grad():\n",
    "                    self.running_mean = (1-self.momentum)*self.running_mean + self.momentum*mu\n",
    "                    self.running_var = (1-self.momentum)*self.running_var + self.momentum*sigma2\n",
    "            y = y - mu.view(-1,1)\n",
    "            y = y / (sigma2.view(-1,1)**.5 + self.eps)\n",
    "\n",
    "        y = self.weight.view(-1, 1) * y + self.bias.view(-1, 1)\n",
    "        return y.view(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet2(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (prelu1): PReLU(num_parameters=1)\n",
      "  (bn1): CustomBatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (prelu2): PReLU(num_parameters=1)\n",
      "  (bn2): CustomBatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LeNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, (5,5), padding=2)\n",
    "        self.prelu1 = nn.PReLU()\n",
    "#        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.bn1 = CustomBatchNorm2d(6)\n",
    "        self.conv2 = nn.Conv2d(6, 16, (5,5))\n",
    "        self.prelu2 = nn.PReLU()\n",
    "#        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.bn2 = CustomBatchNorm2d(16)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(self.bn1(self.prelu1(self.conv1(x))), (2,2))\n",
    "        x = F.max_pool2d(self.bn2(self.prelu2(self.conv2(x))), (2,2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.1)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net2 = LeNet2()\n",
    "print (net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net2.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; Accuracy train: 95.312%\n",
      "Epoch: 1; Accuracy train: 97.720%\n",
      "Epoch: 2; Accuracy train: 98.040%\n",
      "Epoch: 3; Accuracy train: 98.133%\n",
      "Epoch: 4; Accuracy train: 98.365%\n",
      "Epoch: 5; Accuracy train: 98.360%\n",
      "Epoch: 6; Accuracy train: 98.468%\n",
      "Epoch: 7; Accuracy train: 98.552%\n",
      "Epoch: 8; Accuracy train: 98.540%\n",
      "Epoch: 9; Accuracy train: 92.765%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    # trainning\n",
    "    av_loss = 0.\n",
    "    correct = 0.\n",
    "    for x, y in train_loader:\n",
    "        # рассчитываем функцию потерь\n",
    "        out = net2(x)\n",
    "        loss = criterion(out, y)\n",
    "        # оптимизация параметров\n",
    "        ## первым шагом обнулим градиенты предыдущего шага (важный момент,\n",
    "        ## без этого результаты теряют корректность)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # подсчет статистики за эпоху        \n",
    "        pred = out.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "        av_loss += loss.item()\n",
    "    print('Epoch: {}; Accuracy train: {:.3f}%'.format(epoch, correct / len(train_loader.dataset) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9; Accuracy train: 98.190%\n"
     ]
    }
   ],
   "source": [
    "av_loss = 0.\n",
    "correct = 0.\n",
    "for x, y in test_loader:\n",
    "    # рассчитываем функцию потерь\n",
    "    out = net2(x)\n",
    "    loss = criterion(out, y)\n",
    "    # подсчет статистики за эпоху        \n",
    "    pred = out.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "    av_loss += loss.item()\n",
    "print('Epoch: {}; Accuracy train: {:.3f}%'.format(epoch, correct / len(test_loader.dataset) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import Optimizer, required\n",
    "import copy\n",
    "\n",
    "class MyRMSProp(Optimizer):\n",
    "    \n",
    "    def __init__(self, params, lr=1e-2, alpha=0.9, eps=1e-8):\n",
    "        defaults = dict(lr=lr, alpha=alpha, eps=eps)\n",
    "        super(MyRMSProp, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(MyRMSProp, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            alpha = group['alpha']\n",
    "            lr = group['lr']\n",
    "            eps = group['eps']\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad.data\n",
    "                state = self.state[p]\n",
    "                if len(state) == 0:\n",
    "                    state['grad_squared'] = torch.zeros_like(p.data)\n",
    "\n",
    "                grad_squared = state['grad_squared']\n",
    "\n",
    "                grad_squared.mul_(alpha)\n",
    "                grad_squared.addcmul_(1-alpha, d_p, d_p)\n",
    "\n",
    "                grad_avg = grad_squared.sqrt().add_(eps)\n",
    "\n",
    "                p.data.addcdiv_(-lr, d_p, grad_avg)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, (5,5), padding=2)\n",
    "        self.prelu1 = nn.PReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "#        self.bn1 = CustomBatchNorm2d(6)\n",
    "        self.conv2 = nn.Conv2d(6, 16, (5,5))\n",
    "        self.prelu2 = nn.PReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(self.bn1(self.prelu1(self.conv1(x))), (2,2))\n",
    "        x = F.max_pool2d(self.bn2(self.prelu2(self.conv2(x))), (2,2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.1)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (prelu1): PReLU(num_parameters=1)\n",
      "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (prelu2): PReLU(num_parameters=1)\n",
      "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net_rmsprop = LeNet()\n",
    "print (net_rmsprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = MyRMSProp(net_rmsprop.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; Accuracy train: 94.608%\n",
      "Epoch: 1; Accuracy train: 96.972%\n",
      "Epoch: 2; Accuracy train: 97.122%\n",
      "Epoch: 3; Accuracy train: 96.807%\n",
      "Epoch: 4; Accuracy train: 96.702%\n",
      "Epoch: 5; Accuracy train: 96.320%\n",
      "Epoch: 6; Accuracy train: 95.513%\n",
      "Epoch: 7; Accuracy train: 95.472%\n",
      "Epoch: 8; Accuracy train: 94.670%\n",
      "Epoch: 9; Accuracy train: 94.370%\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # trainning\n",
    "    av_loss = 0.\n",
    "    correct = 0.\n",
    "    for x, y in train_loader:\n",
    "        # рассчитываем функцию потерь\n",
    "        out = net_rmsprop(x)\n",
    "        loss = criterion(out, y)\n",
    "        # оптимизация параметров\n",
    "        ## первым шагом обнулим градиенты предыдущего шага (важный момент,\n",
    "        ## без этого результаты теряют корректность)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # подсчет статистики за эпоху        \n",
    "        pred = out.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "        av_loss += loss.item()\n",
    "    print('Epoch: {}; Accuracy train: {:.3f}%'.format(epoch, correct / len(train_loader.dataset) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD vs. RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (prelu1): PReLU(num_parameters=1)\n",
      "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (prelu2): PReLU(num_parameters=1)\n",
      "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net_sgd = LeNet()\n",
    "print (net_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net_sgd.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; Accuracy train: 90.077%\n",
      "Epoch: 1; Accuracy train: 97.587%\n",
      "Epoch: 2; Accuracy train: 98.248%\n",
      "Epoch: 3; Accuracy train: 98.635%\n",
      "Epoch: 4; Accuracy train: 98.790%\n",
      "Epoch: 5; Accuracy train: 98.902%\n",
      "Epoch: 6; Accuracy train: 99.080%\n",
      "Epoch: 7; Accuracy train: 99.195%\n",
      "Epoch: 8; Accuracy train: 99.242%\n",
      "Epoch: 9; Accuracy train: 99.277%\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # trainning\n",
    "    av_loss = 0.\n",
    "    correct = 0.\n",
    "    for x, y in train_loader:\n",
    "        # рассчитываем функцию потерь\n",
    "        out = net_sgd(x)\n",
    "        loss = criterion(out, y)\n",
    "        # оптимизация параметров\n",
    "        ## первым шагом обнулим градиенты предыдущего шага (важный момент,\n",
    "        ## без этого результаты теряют корректность)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # подсчет статистики за эпоху        \n",
    "        pred = out.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "        av_loss += loss.item()\n",
    "    print('Epoch: {}; Accuracy train: {:.3f}%'.format(epoch, correct / len(train_loader.dataset) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSProp Accuracy test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9; Accuracy test: 91.270%\n"
     ]
    }
   ],
   "source": [
    "av_loss = 0.\n",
    "correct = 0.\n",
    "for x, y in test_loader:\n",
    "    # рассчитываем функцию потерь\n",
    "    out = net_rmsprop(x)\n",
    "    loss = criterion(out, y)\n",
    "    # подсчет статистики за эпоху        \n",
    "    pred = out.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "    av_loss += loss.item()\n",
    "print('Epoch: {}; Accuracy test: {:.3f}%'.format(epoch, correct / len(test_loader.dataset) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Accuracy test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9; Accuracy test: 98.890%\n"
     ]
    }
   ],
   "source": [
    "av_loss = 0.\n",
    "correct = 0.\n",
    "for x, y in test_loader:\n",
    "    # рассчитываем функцию потерь\n",
    "    out = net_sgd(x)\n",
    "    loss = criterion(out, y)\n",
    "    # подсчет статистики за эпоху        \n",
    "    pred = out.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "    av_loss += loss.item()\n",
    "print('Epoch: {}; Accuracy test: {:.3f}%'.format(epoch, correct / len(test_loader.dataset) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
