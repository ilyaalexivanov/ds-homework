{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import wordnet\n",
    "import enchant\n",
    "from nltk.metrics import edit_distance\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data, JSON to CVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEWS = 100000\n",
    "data_list = list()\n",
    "columns = ['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'text', 'date']\n",
    "\n",
    "with open('yelp_training_set_review.json') as reviews:\n",
    "    import json\n",
    "    for i, line in enumerate(reviews):\n",
    "\n",
    "        if i == REVIEWS:\n",
    "            break\n",
    "        data = json.loads(line)\n",
    "        data_list.append([data['review_id'],\n",
    "                          data['user_id'],\n",
    "                          data['business_id'],\n",
    "                          data['stars'],\n",
    "                          data['votes']['useful'],\n",
    "                          data['votes']['funny'],\n",
    "                          data['votes']['cool'],\n",
    "                          data['text'],\n",
    "                          data['date']])\n",
    "\n",
    "reviews.close()\n",
    "\n",
    "del reviews, i, line, data, REVIEWS\n",
    "df = pd.DataFrame(data_list, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>review_year</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>My wife tok me here on my birthday for breakfa...</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>[M, , , w, , f, e, , , , k, , , e, , h, e, r, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, , h, , v, e, , n, , , , , e, , , w, h, , ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>love the gyro plate. Rice is so god and I also...</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>[l, , v, e, , , h, e, , g, , r, , , p, l, , , ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  fWKvX83p0-ka4JS3dc6E5A  rLtl8ZkDX5vH5nAx9C3q5Q  9yKzy9PApeiPPOUJEtnvkg   \n",
       "1  IjZ33sJrzXqU-0X6U8NwyA  0a2KyEL0d3Yb1V6aivbIuQ  ZRJwVLyzEJq1VAihDhYiow   \n",
       "2  IESLBzqUCLdSzSqm0eCSxQ  0hT2KtfLiobPvh6cDC8JQg  6oRAC4uyJCsJl1X0WZpVSA   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      5       5      0     2   \n",
       "1      5       0      0     0   \n",
       "2      4       1      0     0   \n",
       "\n",
       "                                                text        date  review_year  \\\n",
       "0  My wife tok me here on my birthday for breakfa...  2011-01-26         2011   \n",
       "1  I have no idea why some people give bad review...  2011-07-27         2011   \n",
       "2  love the gyro plate. Rice is so god and I also...  2012-06-14         2012   \n",
       "\n",
       "   sentiment                                       cleaned_text  \n",
       "0          1  [M, , , w, , f, e, , , , k, , , e, , h, e, r, ...  \n",
       "1          1  [I, , h, , v, e, , n, , , , , e, , , w, h, , ,...  \n",
       "2          1  [l, , v, e, , , h, e, , g, , r, , , p, l, , , ...  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 9)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"DVAP....\\n\\nYou have to go at least once in your life. It really is a neat place with alot of history. \\n\\nThe service is great, it appears to be family run. \\n\\nThe food is good. Better then Dennys but not as good as Mimi's. \\n\\nI had the all u can eat of beef ribs, lasagna, meat loaf, cat fish, chicken, mashed and diced potatoes, stuffing, rice, homemade apple pie, etc and salad bar. I know I am missing a bunch of stuff they had but you get the drift. \\n\\nThey run specials on Prime rib and stuff so you might want to call to see what they are serving the night you go.\""
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[20].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete '\\r\\n', '\\n\\n', '\\n', '\\r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Perkins) Python 3 Text Processing with NLTK 3 Cookbook\n",
    "class Newline_Replacer(object):\n",
    "    def replace(self, text):\n",
    "        s = text\n",
    "        s = s.replace('\\r\\n', ' ')\n",
    "        s = s.replace('\\n\\n', ' ') \n",
    "        s = s.replace('\\n', ' ')\n",
    "        s = s.replace('\\r', ' ') \n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Extra spaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Perkins) Python 3 Text Processing with NLTK 3 Cookbook\n",
    "class Extra_Spaces_Replacer(object):\n",
    "    def replace(self, text):\n",
    "        s = text\n",
    "        s = re.sub('\\s\\s+', ' ', s)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Word reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We went here on a Saturday afternoon and this place was incredibly empty.  They had brunch specials going on, including $2 bloody mary\\'s and mimosas, but we were more in the mood for lunch.  Except for the bloody mary, I had to try one.  It came out in a high-ball-sized glass.  Boo!  But it was really tasty. Yay!  The hubby remembered a sign outside the restaurant a few weeks back that said they had Arrogant Bastard, and he got a 22 oz bottle for $4.75.  Hey, that\\'s not fair!!\\n\\nNext up: the wings.  We were a bit hesitant to order them when the waitress informed us that they are \"seasoned\" but not sauced, so they can\\'t be ordered hot.  We did ask for them crispy though, and the waitress even asked the cooks to throw them back in for a few minutes when they came out not visibly crispy.  These non-traditional wings were actually pretty damn good.  The seasoning was a little spicy and salty with just a hint of sweet.  If I were in the mood for the tang and kick of Frank\\'s Hot Sauce, these wouldn\\'t cut it, but otherwise they were good enough to go back again for.\\n\\nMy entree was the Tilapia salad, and I was a bit disappointed.  The fish was a bit dry and uninspired. And the greens underneath were overdressed and wilted.  I ate the greens around the fish and picked out the almonds and Mandarin oranges, but I had to leave the mush hiding underneath the fish.\\n\\nIt wasn\\'t bad enough to say I wouldn\\'t go back, but I won\\'t be anxiously awaiting my next trip.'"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#review with reduction\n",
    "reduction_review = df['text'][16]\n",
    "reduction_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Perkins) Python 3 Text Processing with NLTK 3 Cookbook\n",
    "rep_patterns = [\n",
    "    (r'won\\'t', 'will not'),\n",
    "    (r'can\\'t', 'can not'),\n",
    "    (r'i\\'m', 'i am'),\n",
    "    (r'I\\'m', 'I am'),\n",
    "    (r'ain\\'t', 'is not'),\n",
    "    (r'(\\w+)\\'ll', '\\g<1> will'),\n",
    "    (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "    (r'(\\w+)\\'ve', '\\g<1> have'),\n",
    "    (r'(\\w+)\\'s', '\\g<1> is'),\n",
    "    (r'(\\w+)\\'re', '\\g<1> are'),\n",
    "    (r'(\\w+)\\'d', '\\g<1> would'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Perkins) Python 3 Text Processing with NLTK 3 Cookbook\n",
    "class Word_Reduction_Replacer(object):\n",
    "    def __init__(self, patterns=rep_patterns):\n",
    "        self.patterns = [(re.compile(regex), repl) for (regex, repl) in patterns]\n",
    "    \n",
    "    def replace(self, text):\n",
    "        s = text\n",
    "\n",
    "        for (pattern, repl) in self.patterns:\n",
    "            s = re.sub(pattern, repl, s)\n",
    "\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete repeating letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>Vnr2wuBXEjbLtfQT_XuDSQ</td>\n",
       "      <td>UrXg7zOknA7WAHD60JnK9g</td>\n",
       "      <td>YCCDMLcb7UW8G-o_HsWiiA</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Awesome food anyone??? Go check out Modern Ste...</td>\n",
       "      <td>2011-04-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   review_id                 user_id             business_id  \\\n",
       "1443  Vnr2wuBXEjbLtfQT_XuDSQ  UrXg7zOknA7WAHD60JnK9g  YCCDMLcb7UW8G-o_HsWiiA   \n",
       "\n",
       "      stars  useful  funny  cool  \\\n",
       "1443      5       0      0     0   \n",
       "\n",
       "                                                   text        date  \n",
       "1443  Awesome food anyone??? Go check out Modern Ste...  2011-04-03  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazing_reviews = df[df.text.str.find('AAAMMMAZZING') != -1]\n",
    "amazing_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Awesome food anyone??? Go check out Modern Steak in Scottsdale, AZ.\\nGorgeous dining room! Excellent service (with our server Gabe)! And the food was AAAMMMAZZING!\\n\\nIt\\'s located at Fashion Mall, but it\\'s NOT a \"mall\" restaurant. A MUST go!'"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_review = amazing_reviews['text'][1443]\n",
    "a_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Perkins) Python 3 Text Processing with NLTK 3 Cookbook \n",
    "class Repeat_Replacer(object):\n",
    "    def __init__(self):\n",
    "        self.repeat_regexp = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "        self.repl = r'\\1\\2\\3'\n",
    "\n",
    "    def replace(self, word):\n",
    "        if wordnet.synsets(word):\n",
    "            return word\n",
    "        \n",
    "        repl_word = self.repeat_regexp.sub(self.repl, word)\n",
    "\n",
    "        if repl_word != word:\n",
    "            return self.replace(repl_word)\n",
    "        else:\n",
    "            return repl_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Perkins) Python 3 Text Processing with NLTK 3 Cookbook\n",
    "\n",
    "class Spelling_Replacer(object):\n",
    "    def __init__(self, dict_name='en', max_dist=1):\n",
    "        self.spell_dict = enchant.Dict(dict_name)\n",
    "        self.max_dist = max_dist\n",
    "    \n",
    "    def replace(self, word):\n",
    "        if self.spell_dict.check(word):\n",
    "            return word\n",
    "    \n",
    "        suggestions = self.spell_dict.suggest(word)\n",
    "    \n",
    "        if suggestions and edit_distance(word, suggestions[0]) <= self.max_dist:\n",
    "            return suggestions[0]\n",
    "        else:\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "newline_replacer = Newline_Replacer()\n",
    "extra_spaces_replacer = Extra_Spaces_Replacer()\n",
    "word_reduction_replacer = Word_Reduction_Replacer()\n",
    "repeat_replacer = Repeat_Replacer()\n",
    "spell_replacer = Spelling_Replacer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(newline_replacer.replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(extra_spaces_replacer.replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(word_reduction_replacer.replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(repeat_replacer.replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['text'] = df['text'].apply(spell_replacer.replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>My wife tok me here on my birthday for breakfa...</td>\n",
       "      <td>2011-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>2011-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>love the gyro plate. Rice is so god and I also...</td>\n",
       "      <td>2012-06-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparal Dog Park!!!...</td>\n",
       "      <td>2010-05-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  fWKvX83p0-ka4JS3dc6E5A  rLtl8ZkDX5vH5nAx9C3q5Q  9yKzy9PApeiPPOUJEtnvkg   \n",
       "1  IjZ33sJrzXqU-0X6U8NwyA  0a2KyEL0d3Yb1V6aivbIuQ  ZRJwVLyzEJq1VAihDhYiow   \n",
       "2  IESLBzqUCLdSzSqm0eCSxQ  0hT2KtfLiobPvh6cDC8JQg  6oRAC4uyJCsJl1X0WZpVSA   \n",
       "3  G-WvGaISbqqaMHlNnByodA  uZetl9T0NcROGOyFfughhg  _1QQZuf4zZOyFCvXc0o6Vg   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      5       5      0     2   \n",
       "1      5       0      0     0   \n",
       "2      4       1      0     0   \n",
       "3      5       2      0     1   \n",
       "\n",
       "                                                text        date  \n",
       "0  My wife tok me here on my birthday for breakfa...  2011-01-26  \n",
       "1  I have no idea why some people give bad review...  2011-07-27  \n",
       "2  love the gyro plate. Rice is so god and I also...  2012-06-14  \n",
       "3  Rosie, Dakota, and I LOVE Chaparal Dog Park!!!...  2010-05-27  "
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_year'] = df['date'].apply(lambda x:int(x[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>review_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>My wife tok me here on my birthday for breakfa...</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>love the gyro plate. Rice is so god and I also...</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  fWKvX83p0-ka4JS3dc6E5A  rLtl8ZkDX5vH5nAx9C3q5Q  9yKzy9PApeiPPOUJEtnvkg   \n",
       "1  IjZ33sJrzXqU-0X6U8NwyA  0a2KyEL0d3Yb1V6aivbIuQ  ZRJwVLyzEJq1VAihDhYiow   \n",
       "2  IESLBzqUCLdSzSqm0eCSxQ  0hT2KtfLiobPvh6cDC8JQg  6oRAC4uyJCsJl1X0WZpVSA   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      5       5      0     2   \n",
       "1      5       0      0     0   \n",
       "2      4       1      0     0   \n",
       "\n",
       "                                                text        date  review_year  \n",
       "0  My wife tok me here on my birthday for breakfa...  2011-01-26         2011  \n",
       "1  I have no idea why some people give bad review...  2011-07-27         2011  \n",
       "2  love the gyro plate. Rice is so god and I also...  2012-06-14         2012  "
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Destribution of reviews by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_year</th>\n",
       "      <th>review_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>2878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>7421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>11634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010</td>\n",
       "      <td>18378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011</td>\n",
       "      <td>27674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012</td>\n",
       "      <td>30767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_year  review_id\n",
       "0         2005         47\n",
       "1         2006        577\n",
       "2         2007       2878\n",
       "3         2008       7421\n",
       "4         2009      11634\n",
       "5         2010      18378\n",
       "6         2011      27674\n",
       "7         2012      30767\n",
       "8         2013        624"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['review_year'])['review_id'].size().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of reviews by star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>review_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>34643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars  review_id\n",
       "0      1       7638\n",
       "1      2       9078\n",
       "2      3      15311\n",
       "3      4      34643\n",
       "4      5      33330"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['stars'])['review_id'].size().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If stars >= 4, sentiment = 1\n",
    "If starts < 4, sentiment = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['stars'].apply(lambda x: 1 if x >= 4 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>review_year</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>My wife tok me here on my birthday for breakfa...</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>love the gyro plate. Rice is so god and I also...</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  fWKvX83p0-ka4JS3dc6E5A  rLtl8ZkDX5vH5nAx9C3q5Q  9yKzy9PApeiPPOUJEtnvkg   \n",
       "1  IjZ33sJrzXqU-0X6U8NwyA  0a2KyEL0d3Yb1V6aivbIuQ  ZRJwVLyzEJq1VAihDhYiow   \n",
       "2  IESLBzqUCLdSzSqm0eCSxQ  0hT2KtfLiobPvh6cDC8JQg  6oRAC4uyJCsJl1X0WZpVSA   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      5       5      0     2   \n",
       "1      5       0      0     0   \n",
       "2      4       1      0     0   \n",
       "\n",
       "                                                text        date  review_year  \\\n",
       "0  My wife tok me here on my birthday for breakfa...  2011-01-26         2011   \n",
       "1  I have no idea why some people give bad review...  2011-07-27         2011   \n",
       "2  love the gyro plate. Rice is so god and I also...  2012-06-14         2012   \n",
       "\n",
       "   sentiment  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  "
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stop_words = stopwords.words('english')\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in english_stop_words])\n",
    "        )\n",
    "    return removed_stop_words\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(lambda x: remove_stop_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ilya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "\n",
    "def get_lemmatized_text(corpus):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: get_lemmatized_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>review_year</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>My wife tok me here on my birthday for breakfa...</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>[M, , , w, , f, e, , , , k, , , e, , h, e, r, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, , h, , v, e, , n, , , , , e, , , w, h, , ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>love the gyro plate. Rice is so god and I also...</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>[l, , v, e, , , h, e, , g, , r, , , p, l, , , ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  fWKvX83p0-ka4JS3dc6E5A  rLtl8ZkDX5vH5nAx9C3q5Q  9yKzy9PApeiPPOUJEtnvkg   \n",
       "1  IjZ33sJrzXqU-0X6U8NwyA  0a2KyEL0d3Yb1V6aivbIuQ  ZRJwVLyzEJq1VAihDhYiow   \n",
       "2  IESLBzqUCLdSzSqm0eCSxQ  0hT2KtfLiobPvh6cDC8JQg  6oRAC4uyJCsJl1X0WZpVSA   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      5       5      0     2   \n",
       "1      5       0      0     0   \n",
       "2      4       1      0     0   \n",
       "\n",
       "                                                text        date  review_year  \\\n",
       "0  My wife tok me here on my birthday for breakfa...  2011-01-26         2011   \n",
       "1  I have no idea why some people give bad review...  2011-07-27         2011   \n",
       "2  love the gyro plate. Rice is so god and I also...  2012-06-14         2012   \n",
       "\n",
       "   sentiment                                       cleaned_text  \n",
       "0          1  [M, , , w, , f, e, , , , k, , , e, , h, e, r, ...  \n",
       "1          1  [I, , h, , v, e, , n, , , , , e, , , w, h, , ,...  \n",
       "2          1  [l, , v, e, , , h, e, , g, , r, , , p, l, , , ...  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_set, X_nottrain, y_train, y_nottrain = train_test_split(df['text'], \n",
    "                                                    df['sentiment'], \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=42)\n",
    "\n",
    "X_test_set, X_val_set, y_test, y_val = train_test_split(X_nottrain, \n",
    "                                                    y_nottrain, \n",
    "                                                    test_size=0.5, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2))\n",
    "cv.fit(X_train_set)\n",
    "X_train = cv.transform(X_train_set)\n",
    "X_test = cv.transform(X_test_set)\n",
    "X_val = cv.transform(X_val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 1527271)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C = 0.01, Accuracy: 0.8686666666666667, F1-score: 0.9072766638426057\n",
      "For C = 0.05, Accuracy: 0.8742666666666666, F1-score: 0.9102161287251261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/envs/otus-ds/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C = 0.25, Accuracy: 0.8724, F1-score: 0.9081573896353168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/envs/otus-ds/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C = 0.5, Accuracy: 0.8712, F1-score: 0.9070707070707071\n",
      "For C = 1, Accuracy: 0.8709333333333333, F1-score: 0.9067796610169492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/envs/otus-ds/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(solver = 'lbfgs', \n",
    "                            penalty = 'l2', \n",
    "                            C=c,\n",
    "                           max_iter= 500)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"For C = %s, Accuracy: %s, F1-score: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val)), f1_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.8708666666666667, F1-score: 0.9080639802553515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/envs/otus-ds/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(solver = 'lbfgs', \n",
    "                            penalty = 'l2', \n",
    "                            C=0.05,\n",
    "                           max_iter= 500)\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s, F1-score: %s\" \n",
    "           % (accuracy_score(y_test, final_model.predict(X_test)), f1_score(y_test, final_model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Positive\n",
      "('amazing', 1.298368034218033)\n",
      "('awesome', 1.1993725960498127)\n",
      "('be disapointed', 1.1848377465096565)\n",
      "('excelent', 1.0995227169481077)\n",
      "('fantastic', 1.0952414410875522)\n",
      "('best', 1.0166890693436077)\n",
      "('delicious', 1.0104628696811564)\n",
      "('love this', 0.9940241156674842)\n",
      "('wonderful', 0.9925348688857923)\n",
      "('incredible', 0.9528211393786559)\n",
      "('five stars', 0.9375527983160354)\n",
      "('not disapointed', 0.9200679316137024)\n",
      "('outstanding', 0.8971206036022086)\n",
      "('so god', 0.8805296311496796)\n",
      "('not only', 0.8644627862287049)\n",
      "Best Negative\n",
      "('worst', -1.6254305221227119)\n",
      "('mediocre', -1.5615553237484752)\n",
      "('not worth', -1.4783554211679928)\n",
      "('meh', -1.3696830951518075)\n",
      "('thre stars', -1.3242540881111635)\n",
      "('overpriced', -1.3237119176294783)\n",
      "('not great', -1.2687255471737127)\n",
      "('terible', -1.256673888292559)\n",
      "('awful', -1.2124375224771267)\n",
      "('bland', -1.2089216347185894)\n",
      "('rude', -1.1849028562582733)\n",
      "('horible', -1.1711069667040277)\n",
      "('sucks', -1.1594219862716861)\n",
      "('at best', -1.1485669128888518)\n",
      "('two stars', -1.0998268805919895)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "print(\"Best Positive\")\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:15]:\n",
    "    print (best_positive)\n",
    "\n",
    "print(\"Best Negative\")\n",
    "\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:15]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C = 0.01, Accuracy: 0.8718666666666667, F1-score: 0.9081437583636016\n",
      "For C = 0.05, Accuracy: 0.8650666666666667, F1-score: 0.9023354564755839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/envs/otus-ds/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C = 0.25, Accuracy: 0.8608666666666667, F1-score: 0.898792493089569\n",
      "For C = 0.5, Accuracy: 0.8574, F1-score: 0.8960893854748605\n",
      "For C = 1, Accuracy: 0.8540666666666666, F1-score: 0.8936294280577286\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c, max_iter=500)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"For C = %s, Accuracy: %s, F1-score: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val)), f1_score(y_val, svm.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.8678, F1-score: 0.9055669317586552\n"
     ]
    }
   ],
   "source": [
    "final_model = LinearSVC(C=0.01, max_iter=500)\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s, F1-score: %s\" \n",
    "           % (accuracy_score(y_test, final_model.predict(X_test)), f1_score(y_test, final_model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
