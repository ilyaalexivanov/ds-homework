{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import wordnet\n",
    "import enchant\n",
    "from nltk.metrics import edit_distance\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data yelp api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_key = 'ZPdOK1WUGHAXLl9TBhGD9GG8p7wjE6TelZtakUyDLbpS0qI92EpxiAuA5OYmdINFO_EcDG4pnqjN_5-BkPGhCOXNUxebMOTFvgTU9XcUEZ4wd7wzDKj35tKqK6LbXXYx'\n",
    "Endpoint = 'https://api.yelp.com/v3/businesses/search'\n",
    "headers = {'Authorization' : 'bearer {}'.format(API_key)}\n",
    "Parameters = {'term':'restaurant', 'limit':50 }\n",
    "data = list()\n",
    "\n",
    "for offset in range(0, 3350, 50):\n",
    "    Parameters.update({'offset': offset})\n",
    "    response = requests.get(url = Endpoint, params = Parameters, headers = headers)\n",
    "    data.append(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded  150 reviews\n",
      "loaded  300 reviews\n",
      "loaded  450 reviews\n",
      "loaded  600 reviews\n",
      "loaded  750 reviews\n",
      "loaded  900 reviews\n",
      "loaded  1050 reviews\n",
      "loaded  1200 reviews\n",
      "loaded  1350 reviews\n",
      "loaded  1500 reviews\n",
      "loaded  1650 reviews\n",
      "loaded  1800 reviews\n",
      "loaded  1950 reviews\n",
      "loaded  2100 reviews\n",
      "loaded  2250 reviews\n",
      "loaded  2400 reviews\n",
      "loaded  2550 reviews\n",
      "loaded  2700 reviews\n",
      "loaded  2850 reviews\n",
      "loaded  3000 reviews\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'businesses'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-29e4b116ea94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubset50\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbiz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubset50\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'businesses'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mEndpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://api.yelp.com/v3/businesses/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbiz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'/reviews'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEndpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'businesses'"
     ]
    }
   ],
   "source": [
    "#headers = {'Authorization' : 'bearer {}'.format(API_key)}\n",
    "Parameters = {}\n",
    "reviews = list()\n",
    "count = 0\n",
    "for subset50 in data:\n",
    "    for biz in subset50['businesses']:\n",
    "        Endpoint = 'https://api.yelp.com/v3/businesses/' + biz['id'] +'/reviews'\n",
    "        response = requests.get(url = Endpoint, params = Parameters, headers = headers)\n",
    "        reviews.append(response.json())\n",
    "    count = count + 1\n",
    "    print(\"loaded \", count*3*50, 'reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_list = list()\n",
    "for reviews3 in reviews:\n",
    "    for review in reviews3['reviews']:\n",
    "#        (review_id, stars, text) = review['id'], review['rating'], review['text']\n",
    "        id_review_text_time = review['id'], review['rating'], review['text'], review['time_created']        \n",
    "        reviews_list.append(id_review_text_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(reviews_list, columns = ['review_id' , 'stars', 'text' , 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_year'] = df['date'].apply(lambda x:int(x[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>review_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7pktjPusbXX1g55uEZqJmw</td>\n",
       "      <td>5</td>\n",
       "      <td>This was the perfect start to my Sunday mornin...</td>\n",
       "      <td>2019-11-26 17:16:27</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vR-BfefUsGAza6MlqEJc5Q</td>\n",
       "      <td>5</td>\n",
       "      <td>A good friend of mine gifted me the Clinton St...</td>\n",
       "      <td>2019-11-22 09:01:54</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W9w6LOUA__Z_LJkrefGSHw</td>\n",
       "      <td>3</td>\n",
       "      <td>I am not sure what the hype is with Clinton St...</td>\n",
       "      <td>2019-11-21 20:43:59</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id  stars  \\\n",
       "0  7pktjPusbXX1g55uEZqJmw      5   \n",
       "1  vR-BfefUsGAza6MlqEJc5Q      5   \n",
       "2  W9w6LOUA__Z_LJkrefGSHw      3   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  This was the perfect start to my Sunday mornin...  2019-11-26 17:16:27   \n",
       "1  A good friend of mine gifted me the Clinton St...  2019-11-22 09:01:54   \n",
       "2  I am not sure what the hype is with Clinton St...  2019-11-21 20:43:59   \n",
       "\n",
       "   review_year  \n",
       "0         2019  \n",
       "1         2019  \n",
       "2         2019  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete '\\r\\n', '\\n\\n', '\\n', '\\r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Perkins) Python 3 Text Processing with NLTK 3 Cookbook\n",
    "class Newline_Replacer(object):\n",
    "    def replace(self, text):\n",
    "        s = text\n",
    "        s = s.replace('\\r\\n', ' ')\n",
    "        s = s.replace('\\n\\n', ' ') \n",
    "        s = s.replace('\\n', ' ')\n",
    "        s = s.replace('\\r', ' ') \n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Extra spaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Perkins) Python 3 Text Processing with NLTK 3 Cookbook\n",
    "class Extra_Spaces_Replacer(object):\n",
    "    def replace(self, text):\n",
    "        s = text\n",
    "        s = re.sub('\\s\\s+', ' ', s)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Word reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Perkins) Python 3 Text Processing with NLTK 3 Cookbook\n",
    "rep_patterns = [\n",
    "    (r'won\\'t', 'will not'),\n",
    "    (r'can\\'t', 'can not'),\n",
    "    (r'i\\'m', 'i am'),\n",
    "    (r'I\\'m', 'I am'),\n",
    "    (r'ain\\'t', 'is not'),\n",
    "    (r'(\\w+)\\'ll', '\\g<1> will'),\n",
    "    (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "    (r'(\\w+)\\'ve', '\\g<1> have'),\n",
    "    (r'(\\w+)\\'s', '\\g<1> is'),\n",
    "    (r'(\\w+)\\'re', '\\g<1> are'),\n",
    "    (r'(\\w+)\\'d', '\\g<1> would'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Perkins) Python 3 Text Processing with NLTK 3 Cookbook\n",
    "class Word_Reduction_Replacer(object):\n",
    "    def __init__(self, patterns=rep_patterns):\n",
    "        self.patterns = [(re.compile(regex), repl) for (regex, repl) in patterns]\n",
    "    \n",
    "    def replace(self, text):\n",
    "        s = text\n",
    "\n",
    "        for (pattern, repl) in self.patterns:\n",
    "            s = re.sub(pattern, repl, s)\n",
    "\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete repeating letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Perkins) Python 3 Text Processing with NLTK 3 Cookbook \n",
    "class Repeat_Replacer(object):\n",
    "    def __init__(self):\n",
    "        self.repeat_regexp = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "        self.repl = r'\\1\\2\\3'\n",
    "\n",
    "    def replace(self, word):\n",
    "        if wordnet.synsets(word):\n",
    "            return word\n",
    "        \n",
    "        repl_word = self.repeat_regexp.sub(self.repl, word)\n",
    "\n",
    "        if repl_word != word:\n",
    "            return self.replace(repl_word)\n",
    "        else:\n",
    "            return repl_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Perkins) Python 3 Text Processing with NLTK 3 Cookbook\n",
    "\n",
    "class Spelling_Replacer(object):\n",
    "    def __init__(self, dict_name='en', max_dist=1):\n",
    "        self.spell_dict = enchant.Dict(dict_name)\n",
    "        self.max_dist = max_dist\n",
    "    \n",
    "    def replace(self, word):\n",
    "        if self.spell_dict.check(word):\n",
    "            return word\n",
    "    \n",
    "        suggestions = self.spell_dict.suggest(word)\n",
    "    \n",
    "        if suggestions and edit_distance(word, suggestions[0]) <= self.max_dist:\n",
    "            return suggestions[0]\n",
    "        else:\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "newline_replacer = Newline_Replacer()\n",
    "extra_spaces_replacer = Extra_Spaces_Replacer()\n",
    "word_reduction_replacer = Word_Reduction_Replacer()\n",
    "repeat_replacer = Repeat_Replacer()\n",
    "spell_replacer = Spelling_Replacer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(newline_replacer.replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(extra_spaces_replacer.replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(word_reduction_replacer.replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(repeat_replacer.replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(spell_replacer.replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>review_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7pktjPusbXX1g55uEZqJmw</td>\n",
       "      <td>5</td>\n",
       "      <td>This was the perfect start to my Sunday mornin...</td>\n",
       "      <td>2019-11-26 17:16:27</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vR-BfefUsGAza6MlqEJc5Q</td>\n",
       "      <td>5</td>\n",
       "      <td>A god friend of mine gifted me the Clinton Str...</td>\n",
       "      <td>2019-11-22 09:01:54</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W9w6LOUA__Z_LJkrefGSHw</td>\n",
       "      <td>3</td>\n",
       "      <td>I am not sure what the hype is with Clinton St...</td>\n",
       "      <td>2019-11-21 20:43:59</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XIho0jlcBxQUsiYCVYkqbg</td>\n",
       "      <td>5</td>\n",
       "      <td>nice fod! We got a nice table. They have so ma...</td>\n",
       "      <td>2019-11-25 05:43:25</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id  stars  \\\n",
       "0  7pktjPusbXX1g55uEZqJmw      5   \n",
       "1  vR-BfefUsGAza6MlqEJc5Q      5   \n",
       "2  W9w6LOUA__Z_LJkrefGSHw      3   \n",
       "3  XIho0jlcBxQUsiYCVYkqbg      5   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  This was the perfect start to my Sunday mornin...  2019-11-26 17:16:27   \n",
       "1  A god friend of mine gifted me the Clinton Str...  2019-11-22 09:01:54   \n",
       "2  I am not sure what the hype is with Clinton St...  2019-11-21 20:43:59   \n",
       "3  nice fod! We got a nice table. They have so ma...  2019-11-25 05:43:25   \n",
       "\n",
       "   review_year  \n",
       "0         2019  \n",
       "1         2019  \n",
       "2         2019  \n",
       "3         2019  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Destribution of reviews by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_year</th>\n",
       "      <th>review_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>2984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_year  review_id\n",
       "0         2012          3\n",
       "1         2017          1\n",
       "2         2018         12\n",
       "3         2019       2984"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['review_year'])['review_id'].size().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of reviews by star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>review_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars  review_id\n",
       "0      1        127\n",
       "1      2        180\n",
       "2      3        393\n",
       "3      4        875\n",
       "4      5       1425"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['stars'])['review_id'].size().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If stars >= 4, sentiment = 1\n",
    "If starts < 4, sentiment = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['stars'].apply(lambda x: 1 if x >= 4 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>review_year</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7pktjPusbXX1g55uEZqJmw</td>\n",
       "      <td>5</td>\n",
       "      <td>This was the perfect start to my Sunday mornin...</td>\n",
       "      <td>2019-11-26 17:16:27</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vR-BfefUsGAza6MlqEJc5Q</td>\n",
       "      <td>5</td>\n",
       "      <td>A god friend of mine gifted me the Clinton Str...</td>\n",
       "      <td>2019-11-22 09:01:54</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W9w6LOUA__Z_LJkrefGSHw</td>\n",
       "      <td>3</td>\n",
       "      <td>I am not sure what the hype is with Clinton St...</td>\n",
       "      <td>2019-11-21 20:43:59</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id  stars  \\\n",
       "0  7pktjPusbXX1g55uEZqJmw      5   \n",
       "1  vR-BfefUsGAza6MlqEJc5Q      5   \n",
       "2  W9w6LOUA__Z_LJkrefGSHw      3   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  This was the perfect start to my Sunday mornin...  2019-11-26 17:16:27   \n",
       "1  A god friend of mine gifted me the Clinton Str...  2019-11-22 09:01:54   \n",
       "2  I am not sure what the hype is with Clinton St...  2019-11-21 20:43:59   \n",
       "\n",
       "   review_year  sentiment  \n",
       "0         2019          1  \n",
       "1         2019          1  \n",
       "2         2019          0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stop_words = stopwords.words('english')\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in english_stop_words])\n",
    "        )\n",
    "    return removed_stop_words\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(lambda x: remove_stop_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ilya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "\n",
    "def get_lemmatized_text(corpus):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: get_lemmatized_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_set, X_nottrain, y_train, y_nottrain = train_test_split(df['text'], \n",
    "                                                    df['sentiment'], \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=42)\n",
    "\n",
    "X_test_set, X_val_set, y_test, y_val = train_test_split(X_nottrain, \n",
    "                                                    y_nottrain, \n",
    "                                                    test_size=0.5, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2))\n",
    "cv.fit(X_train_set)\n",
    "X_train = cv.transform(X_train_set)\n",
    "X_test = cv.transform(X_test_set)\n",
    "X_val = cv.transform(X_val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 34302)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C = 0.01, Accuracy: 0.7377777777777778, F1-score: 0.8479381443298969\n",
      "For C = 0.05, Accuracy: 0.7666666666666667, F1-score: 0.8612945838837517\n",
      "For C = 0.25, Accuracy: 0.7666666666666667, F1-score: 0.857916102841678\n",
      "For C = 0.5, Accuracy: 0.7688888888888888, F1-score: 0.8586956521739131\n",
      "For C = 1, Accuracy: 0.7688888888888888, F1-score: 0.8586956521739131\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(solver = 'lbfgs', \n",
    "                            penalty = 'l2', \n",
    "                            C=c,\n",
    "                           max_iter= 500)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"For C = %s, Accuracy: %s, F1-score: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val)), f1_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.7911111111111111, F1-score: 0.877284595300261\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(solver = 'lbfgs', \n",
    "                            penalty = 'l2', \n",
    "                            C=0.25,\n",
    "                           max_iter= 500)\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s, F1-score: %s\" \n",
    "           % (accuracy_score(y_test, final_model.predict(X_test)), f1_score(y_test, final_model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Positive\n",
      "('delicious', 0.647324913390588)\n",
      "('excelent', 0.6296718845487629)\n",
      "('amazing', 0.6010545525994486)\n",
      "('spot', 0.5934995661428131)\n",
      "('the best', 0.510448554136048)\n",
      "('loved', 0.49278528175454245)\n",
      "('cozy', 0.45028331077467987)\n",
      "('perfect', 0.43812461583068724)\n",
      "('dishes', 0.43006198205893337)\n",
      "('best', 0.4294134104402576)\n",
      "('glad', 0.41625494914674843)\n",
      "('was great', 0.40272593243449223)\n",
      "('find', 0.40270864956673325)\n",
      "('go', 0.4009883537404277)\n",
      "('pork', 0.38712647507835346)\n",
      "Best Negative\n",
      "('ok', -0.6792476913284964)\n",
      "('reviews', -0.636617266136754)\n",
      "('who', -0.6324898407365795)\n",
      "('terible', -0.580288699807557)\n",
      "('disapointed', -0.5677040595298375)\n",
      "('other', -0.5606252967175549)\n",
      "('this place', -0.5562274347483906)\n",
      "('service', -0.5523607029324997)\n",
      "('few', -0.546669382832302)\n",
      "('average', -0.517830734353114)\n",
      "('like', -0.4435788051535116)\n",
      "('excited', -0.4391506524854406)\n",
      "('bad', -0.4270176639740535)\n",
      "('however the', -0.4145313852911916)\n",
      "('not', -0.40941320096011613)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "print(\"Best Positive\")\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:15]:\n",
    "    print (best_positive)\n",
    "\n",
    "print(\"Best Negative\")\n",
    "\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:15]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C = 0.001, Accuracy: 0.7377777777777778, F1-score: 0.8479381443298969\n",
      "For C = 0.01, Accuracy: 0.7711111111111111, F1-score: 0.8617449664429531\n",
      "For C = 0.05, Accuracy: 0.7644444444444445, F1-score: 0.8559782608695652\n",
      "For C = 0.25, Accuracy: 0.7622222222222222, F1-score: 0.8532235939643347\n",
      "For C = 0.5, Accuracy: 0.7622222222222222, F1-score: 0.8532235939643347\n",
      "For C = 1, Accuracy: 0.7622222222222222, F1-score: 0.8532235939643347\n"
     ]
    }
   ],
   "source": [
    "for c in [0.001, 0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c, max_iter=500)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"For C = %s, Accuracy: %s, F1-score: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val)), f1_score(y_val, svm.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.7977777777777778, F1-score: 0.882882882882883\n"
     ]
    }
   ],
   "source": [
    "final_model = LinearSVC(C=0.01, max_iter=500)\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s, F1-score: %s\" \n",
    "           % (accuracy_score(y_test, final_model.predict(X_test)), f1_score(y_test, final_model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
